{"pageProps":{"content":"\n              <a id=\"一、介绍\" style='display: block; height: 35px;'></a>\n              <h2>\n                一、介绍\n              </h2>\n            <p>Kafka Source</p>\n\n              <a id=\"二、支持版本\" style='display: block; height: 35px;'></a>\n              <h2>\n                二、支持版本\n              </h2>\n            <p>kafka主流版本</p>\n\n              <a id=\"三、插件名称\" style='display: block; height: 35px;'></a>\n              <h2>\n                三、插件名称\n              </h2>\n            <table>\n<thead>\n<tr>\n<th>Sync</th>\n<th>kafkasource、kafkareader</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SQL</td>\n<td>kafka-x</td>\n</tr>\n<tr>\n<td>SQL(upsert)</td>\n<td>upsert-kafka-x</td>\n</tr>\n</tbody></table>\n\n              <a id=\"四、参数说明\" style='display: block; height: 35px;'></a>\n              <h2>\n                四、参数说明\n              </h2>\n            \n              <a id=\"1、Sync\" style='display: block; height: 35px;'></a>\n              <h3>\n                1、Sync\n              </h3>\n            <ul>\n<li><strong>topic</strong><ul>\n<li>描述：要消费的topic，多个以,分割，当<code>mode</code>为<code>timestamp</code>、<code>specific-offsets</code>时不支持多topic</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>mode</strong><ul>\n<li>描述：kafka消费端启动模式，目前仅支持<code>kafkareader</code>插件</li>\n<li>可选值：<ul>\n<li>group-offsets：     从ZK / Kafka brokers中指定的消费组已经提交的offset开始消费</li>\n<li>earliest-offset：    从最早的偏移量开始(如果可能)</li>\n<li>latest-offset：      从最新的偏移量开始(如果可能)</li>\n<li>timestamp：         从每个分区的指定的时间戳开始</li>\n<li>specific-offsets： 从每个分区的指定的特定偏移量开始</li>\n</ul>\n</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：group-offsets</li>\n</ul>\n</li>\n<li><strong>timestamp</strong><ul>\n<li>描述：指定的kafka时间戳采集起点，目前仅支持<code>kafkareader</code>插件</li>\n<li>必选：当<code>mode</code>为<code>timestamp</code>时必选</li>\n<li>字段类型：Long</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>offset</strong><ul>\n<li>描述：消费的分区及对应的特定偏移量，目前仅支持<code>kafkareader</code>插件</li>\n<li>必选：当<code>mode</code>为<code>specific-offsets</code>时必选</li>\n<li>字段类型：String</li>\n<li>格式：partition:0,offset:42;partition:1,offset:300;partition:2,offset:300</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>groupId</strong><ul>\n<li>描述：kafka消费组Id</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：default</li>\n</ul>\n</li>\n<li><strong>encoding</strong><ul>\n<li>描述：字符编码</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：UTF-8</li>\n</ul>\n</li>\n<li><strong>codec</strong><ul>\n<li>描述：编码解码器类型，支持 json、text<ul>\n<li>text：\n将kafka获取到的消息字符串存储到一个key为message的map中，如：kafka中的消息为：{&quot;key&quot;:&quot;key&quot;,&quot;message&quot;:&quot;value&quot;}，\n则发送至下游的数据格式为：</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-json\">[\n    {\n        <span class=\"hljs-string\">&quot;message&quot;</span>:<span class=\"hljs-string\">&quot;{<span class=\"hljs-subst\">\\&quot;</span>key<span class=\"hljs-subst\">\\&quot;</span>: <span class=\"hljs-subst\">\\&quot;</span>key<span class=\"hljs-subst\">\\&quot;</span>, <span class=\"hljs-subst\">\\&quot;</span>value<span class=\"hljs-subst\">\\&quot;</span>: <span class=\"hljs-subst\">\\&quot;</span>value<span class=\"hljs-subst\">\\&quot;</span>}&quot;</span>\n    }\n]\n</code></pre>\n<ul>\n<li>json：将kafka获取到的消息字符串按照json格式进行解析<ul>\n<li>若该字符串为json格式<ul>\n<li>当其中含有message字段时，发送至下游的数据格式为：</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-json\">[\n    {\n        <span class=\"hljs-string\">&quot;key&quot;</span>:<span class=\"hljs-string\">&quot;key&quot;</span>,\n        <span class=\"hljs-string\">&quot;message&quot;</span>:<span class=\"hljs-string\">&quot;value&quot;</span>\n    }\n]\n</code></pre>\n<pre><code>  - 当其中不包含<span class=\"hljs-keyword\">message</span>字段时，增加一个<span class=\"hljs-keyword\">key</span>为<span class=\"hljs-keyword\">message</span>，value为原始消息字符串的键值对，发送至下游的数据格式为： \n</code></pre>\n<pre><code class=\"language-json\">[\n    {\n        <span class=\"hljs-string\">&quot;key&quot;</span>:<span class=\"hljs-string\">&quot;key&quot;</span>,\n        <span class=\"hljs-string\">&quot;value&quot;</span>:<span class=\"hljs-string\">&quot;value&quot;</span>,\n        <span class=\"hljs-string\">&quot;message&quot;</span>:<span class=\"hljs-string\">&quot;{<span class=\"hljs-subst\">\\&quot;</span>key<span class=\"hljs-subst\">\\&quot;</span>: <span class=\"hljs-subst\">\\&quot;</span>key<span class=\"hljs-subst\">\\&quot;</span>, <span class=\"hljs-subst\">\\&quot;</span>value<span class=\"hljs-subst\">\\&quot;</span>: <span class=\"hljs-subst\">\\&quot;</span>value<span class=\"hljs-subst\">\\&quot;</span>}&quot;</span>\n    }\n]\n</code></pre>\n<pre><code>  - 若改字符串不为<span class=\"hljs-type\">json</span>格式，则按照<span class=\"hljs-type\">text</span>类型进行处理\n</code></pre>\n<ul>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：text</li>\n<li><strong>consumerSettings</strong><ul>\n<li>描述：kafka连接配置，支持所有<code>kafka.consumer.ConsumerConfig.ConsumerConfig</code>中定义的配置</li>\n<li>必选：是</li>\n<li>字段类型：Map</li>\n<li>默认值：无</li>\n<li>如：</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-json\"><span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-attr\">&quot;consumerSettings&quot;</span><span class=\"hljs-punctuation\">:</span><span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-attr\">&quot;bootstrap.servers&quot;</span><span class=\"hljs-punctuation\">:</span><span class=\"hljs-string\">&quot;host1:9092,host2:9092,host3:9092&quot;</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n<ul>\n<li><strong>column</strong><ul>\n<li>描述：kafka向MySQL写数据时，对应MySQL表中的字段名</li>\n<li>必选：否</li>\n<li>字段类型：List</li>\n<li>默认值：无</li>\n<li>注意：需指定字段的具体信息，属性说明：<ul>\n<li>name：字段名称</li>\n<li>type：字段类型，可以和数据库里的字段类型不一样，程序会做一次类型转换</li>\n<li>format：如果字段是时间字符串，可以指定时间的格式，将字段类型转为日期格式返回</li>\n<li>如：</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-json\">{\n   <span class=\"hljs-string\">&quot;column&quot;</span>: [\n      {\n         <span class=\"hljs-string\">&quot;name&quot;</span>: <span class=\"hljs-string\">&quot;col&quot;</span>,\n         <span class=\"hljs-string\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;datetime&quot;</span>,\n         <span class=\"hljs-string\">&quot;format&quot;</span>: <span class=\"hljs-string\">&quot;yyyy-MM-dd hh:mm:ss&quot;</span>\n      }\n   ]\n}\n</code></pre>\n\n              <a id=\"2、SQL\" style='display: block; height: 35px;'></a>\n              <h3>\n                2、SQL\n              </h3>\n            <p>具体可以参考：<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kafka.html\">kafka-connector</a></p>\n<ul>\n<li><strong>connector</strong><ul>\n<li>描述：kafka-x</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>topic</strong><ul>\n<li>描述：当表用作源时要从中读取数据的主题名称。它还通过用分号分隔主题来支持源的主题列表，如&#39;topic-1;topic-2&#39;. 请注意，只能为源指定“topic-pattern”和“topic”之一。当表用作接收器时，主题名称是要写入数据的主题。接收器不支持注意主题列表。</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>topic-pattern</strong><ul>\n<li>描述：要从中读取的主题名称模式的正则表达式。当作业开始运行时，消费者将订阅名称与指定正则表达式匹配的所有主题。请注意，只能为源指定“topic-pattern”和“topic”之一。</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>properties.bootstrap.servers</strong><ul>\n<li>描述：逗号分隔的 Kafka 代理列表。</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>properties.group.id</strong><ul>\n<li>描述：Kafka source的消费组id，Kafka sink可选。</li>\n<li>必选：required by source</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>properties.</strong>*<ul>\n<li>描述：这可以设置和传递任意 Kafka 配置。后缀名称必须与<a href=\"https://kafka.apache.org/documentation/#configuration\">Kafka 配置文档中</a>定义的配置键匹配。Flink 将删除“属性”。键前缀并将转换后的键和值传递给底层 KafkaClient。例如，您可以通过 禁用自动主题创建&#39;properties.allow.auto.create.topics&#39; = &#39;false&#39;。但是有一些配置是不支持设置的，因为 Flink 会覆盖它们。</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>format</strong><ul>\n<li>描述：用于反序列化和序列化 Kafka 消息的值部分的格式。有关更多详细信息和更多<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/\">格式</a>选项，请参阅格式页面。注意：此选项或&#39;value.format&#39;选项都是必需的。</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>key.format</strong><ul>\n<li>描述：用用于反序列化和序列化 Kafka 消息关键部分的格式。有关更多详细信息和更多<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/\">格式</a>选项，请参阅格式页面。注意：如果定义了密钥格式，则该&#39;key.fields&#39; 选项也是必需的。否则 Kafka 记录将有一个空键。</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>key.fields</strong><ul>\n<li>描述：定义表架构中物理列的显式列表，用于配置键格式的数据类型。默认情况下，此列表为空，因此未定义键。该列表应如下所示&#39;field1;field2&#39;。</li>\n<li>必选：否</li>\n<li>字段类型：List</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>key.fields-prefix</strong><ul>\n<li>描述：为键格式的所有字段定义自定义前缀，以避免与值格式的字段发生名称冲突。默认情况下，前缀为空。如果定义了自定义前缀，则表架构 和&#39;key.fields&#39;都将使用前缀名称。在构造密钥格式的数据类型时，将删除前缀，并在密钥格式中使用非前缀名称。请注意，此选项要求&#39;value.fields-include&#39; 必须设置为&#39;EXCEPT_KEY&#39;。</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>value.format</strong><ul>\n<li>描述：用于反序列化和序列化 Kafka 消息的值部分的格式。有关更多详细信息和更多格式选项，请参阅格式页面。注意：此选项或&#39;format&#39;<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/\">选项</a>都是必需的。</li>\n<li>必选：是</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>value.fields-include</strong><ul>\n<li>描述：定义如何处理值格式的数据类型中的键列的策略。默认情况下，&#39;ALL&#39;表模式的物理列将包含在值格式中，这意味着键列出现在键和值格式的数据类型中</li>\n<li>必选：否</li>\n<li>字段类型：枚举<ul>\n<li>可选的值：[ALL, EXCEPT_KEY]</li>\n</ul>\n</li>\n<li>默认值：ALL</li>\n</ul>\n</li>\n<li><strong>scan.startup.mode</strong><ul>\n<li>描述：kafka消费的启动模式，有效值为&#39;earliest-offset&#39;，&#39;latest-offset&#39;，&#39;group-offsets&#39;，&#39;timestamp&#39;和&#39;specific-offsets&#39;。有关更多详细信息，请参阅以下<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kafka.html#start-reading-position\">开始阅读位置</a>。upsert模式此参数不生效，写死从earliest-offset处消费</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：group-offsets</li>\n</ul>\n</li>\n<li><strong>scan.startup.specific-offsets</strong><ul>\n<li>描述：在&#39;specific-offsets&#39;启动模式下为每个分区指定偏移量，例如&#39;partition:0,offset:42;partition:1,offset:300&#39;.</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>scan.startup.timestamp-millis</strong><ul>\n<li>描述：从&#39;timestamp&#39;启动模式下使用的指定纪元时间戳（毫秒）开始。</li>\n<li>必选：否</li>\n<li>字段类型：Long</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>scan.topic-partition-discovery.interval</strong><ul>\n<li>描述：消费者定期发现动态创建的 Kafka 主题和分区的时间间隔。</li>\n<li>必选：否</li>\n<li>字段类型：Duration</li>\n<li>默认值：无</li>\n</ul>\n</li>\n<li><strong>sink.partitioner</strong><ul>\n<li>描述： 从 Flink 的分区到 Kafka 的分区的输出分区。有效值为</li>\n<li>default: 使用 kafka 默认分区器对记录进行分区。</li>\n<li>fixed：每个 Flink 分区最终最多包含一个 Kafka 分区。</li>\n<li>round-robin：一个 Flink 分区被分发到 Kafka 分区粘性循环。它仅在未指定记录的键时有效。</li>\n<li>自定义FlinkKafkaPartitioner子类：例如&#39;org.mycompany.MyPartitioner&#39;.</li>\n<li>有关更多详细信息，请参阅以下<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kafka.html#sink-partitioning\">接收器分区</a>。</li>\n<li>必选：否</li>\n<li>字段类型：String</li>\n<li>默认值：default</li>\n</ul>\n</li>\n<li><strong>scan.parallelism</strong><ul>\n<li>描述：定义 Kafka sink 操作符的并行性。默认情况下，并行度由框架使用与上游链式运算符相同的并行度确定。</li>\n<li>必选：否</li>\n<li>字段类型：Integer</li>\n<li>默认值：无</li>\n</ul>\n</li>\n</ul>\n\n              <a id=\"五、数据类型\" style='display: block; height: 35px;'></a>\n              <h2>\n                五、数据类型\n              </h2>\n            <table>\n<thead>\n<tr>\n<th>支持</th>\n<th>BOOLEAN、TINYINT、SMALLINT、INT、BIGINT、FLOAT、DOUBLE、DECIMAL、STRING、VARCHAR、CHAR、TIMESTAMP、DATE、BINARY、ARRAY、MAP、STRUCT、LIST、ROW</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>暂不支持</td>\n<td>其他</td>\n</tr>\n</tbody></table>\n\n              <a id=\"六、脚本示例\" style='display: block; height: 35px;'></a>\n              <h2>\n                六、脚本示例\n              </h2>\n            <p>见项目内<code>chunjun-examples</code>文件夹。</p>\n","tree":[{"label":"ChunJun通用配置详解","category":"file"},{"label":"快速开始","category":"file"},{"label":"ChunJun拓展数据格式","children":[{"label":"protobuf-x","path":"protobuf-x","category":"file"}],"category":"dir"},{"label":"ChunJun连接器","children":[{"label":"binlog","category":"dir","children":[{"label":"binlog-source","path":"binlog-source","category":"file"}]},{"label":"clickhouse","category":"dir","children":[{"label":"clickhouse-lookup","path":"clickhouse-lookup","category":"file"},{"label":"clickhouse-sink","path":"clickhouse-sink","category":"file"},{"label":"clickhouse-source","path":"clickhouse-source","category":"file"}]},{"label":"db2","category":"dir","children":[{"label":"db2-lookup","path":"db2-lookup","category":"file"},{"label":"db2-sink","path":"db2-sink","category":"file"},{"label":"db2-source","path":"db2-source","category":"file"}]},{"label":"dm","category":"dir","children":[{"label":"dm-sink","path":"dm-sink","category":"file"},{"label":"dm-source","path":"dm-source","category":"file"}]},{"label":"doris","category":"dir","children":[{"label":"dorisbatch-sink","path":"dorisbatch-sink","category":"file"}]},{"label":"elasticsearch","category":"dir","children":[{"label":"es7-lookup","path":"es7-lookup","category":"file"},{"label":"es7-sink","path":"es7-sink","category":"file"},{"label":"es7-source","path":"es7-source","category":"file"}]},{"label":"gbase","category":"dir","children":[{"label":"gbase-lookup","path":"gbase-lookup","category":"file"},{"label":"gbase-sink","path":"gbase-sink","category":"file"},{"label":"gbase-source","path":"gbase-source","category":"file"}]},{"label":"greenplum","category":"dir","children":[{"label":"greenplum-sink","path":"greenplum-sink","category":"file"},{"label":"greenplum-source","path":"greenplum-source","category":"file"}]},{"label":"hbase","category":"dir","children":[{"label":"hbase-lookup","path":"hbase-lookup","category":"file"},{"label":"hbase-sink","path":"hbase-sink","category":"file"},{"label":"hbase-source","path":"hbase-source","category":"file"}]},{"label":"hdfs","category":"dir","children":[{"label":"hdfs-sink","path":"hdfs-sink","category":"file"},{"label":"hdfs-source","path":"hdfs-source","category":"file"}]},{"label":"hive","category":"dir","children":[{"label":"hive-lookup","path":"hive-lookup","category":"file"},{"label":"hive-sink","path":"hive-sink","category":"file"}]},{"label":"influxdb","category":"dir","children":[{"label":"influxdb-sink","path":"influxdb-sink","category":"file"},{"label":"influxdb-source","path":"influxdb-source","category":"file"}]},{"label":"kafka","category":"dir","children":[{"label":"kafka-sink","path":"kafka-sink","category":"file"},{"label":"kafka-source","path":"kafka-source","category":"file"}]},{"label":"kingbase","category":"dir","children":[{"label":"kingbase-sink","path":"kingbase-sink","category":"file"},{"label":"kingbase-source","path":"kingbase-source","category":"file"}]},{"label":"kudu","category":"dir","children":[{"label":"kudu-lookup","path":"kudu-lookup","category":"file"},{"label":"kudu-sink","path":"kudu-sink","category":"file"},{"label":"kudu-source","path":"kudu-source","category":"file"}]},{"label":"logminer","category":"dir","children":[{"label":"LogMiner-source","path":"LogMiner-source","category":"file"},{"label":"LogMiner原理","path":"LogMiner原理","category":"file"},{"label":"LogMiner配置","path":"LogMiner配置","category":"file"}]},{"label":"mongodb","category":"dir","children":[{"label":"mongodb-lookup","path":"mongodb-lookup","category":"file"},{"label":"mongodb-sink","path":"mongodb-sink","category":"file"},{"label":"mongodb-source","path":"mongodb-source","category":"file"}]},{"label":"mysql","category":"dir","children":[{"label":"mysql-lookup","path":"mysql-lookup","category":"file"},{"label":"mysql-sink","path":"mysql-sink","category":"file"},{"label":"mysql-source","path":"mysql-source","category":"file"}]},{"label":"oracle","category":"dir","children":[{"label":"oracle-lookup","path":"oracle-lookup","category":"file"},{"label":"oracle-sink","path":"oracle-sink","category":"file"},{"label":"oracle-source","path":"oracle-source","category":"file"}]},{"label":"pgwal","category":"dir","children":[{"label":"Postgres-CDC","path":"Postgres-CDC","category":"file"}]},{"label":"postgresql","category":"dir","children":[{"label":"postgres-lookup","path":"postgres-lookup","category":"file"},{"label":"postgres-sink","path":"postgres-sink","category":"file"},{"label":"postgres-source","path":"postgres-source","category":"file"}]},{"label":"rocketmq","category":"dir","children":[{"label":"rocketmq-source","path":"rocketmq-source","category":"file"}]},{"label":"saphana","category":"dir","children":[{"label":"saphana-sink","path":"saphana-sink","category":"file"},{"label":"saphana-source","path":"saphana-source","category":"file"}]},{"label":"sqlserver","category":"dir","children":[{"label":"sqlserver-lookup","path":"sqlserver-lookup","category":"file"},{"label":"sqlserver-sink","path":"sqlserver-sink","category":"file"},{"label":"sqlserver-source","path":"sqlserver-source","category":"file"}]},{"label":"sqlservercdc","category":"dir","children":[{"label":"SqlServer CDC实时采集原理","path":"SqlServer CDC实时采集原理","category":"file"},{"label":"SqlServer配置CDC","path":"SqlServer配置CDC","category":"file"},{"label":"SqlserverCDC-source","path":"SqlserverCDC-source","category":"file"}]}],"category":"dir"},{"label":"开发者指南","children":[{"label":"如何提交一个优秀的PR","path":"如何提交一个优秀的PR","category":"file"},{"label":"如何自定义插件","path":"如何自定义插件","category":"file"}],"category":"dir"},{"label":"拓展功能","children":[{"label":"增量同步介绍","path":"增量同步介绍","category":"file"},{"label":"断点续传介绍","path":"断点续传介绍","category":"file"},{"label":"脏数据插件设计","path":"脏数据插件设计","category":"file"}],"category":"dir"}],"toc":[{"text":"一、介绍","level":2,"id":"cea35da4-bb64-4e72-b11c-e856825fa424"},{"text":"二、支持版本","level":2,"id":"6e9cbb5a-66d3-4a78-b582-cbaeefd8bb90"},{"text":"三、插件名称","level":2,"id":"71420dee-dc47-4eb8-a31e-684eb3ef67bb"},{"text":"四、参数说明","level":2,"id":"405de4ac-0efe-413d-ab90-1bb453852dbe"},{"text":"1、Sync","level":3,"id":"da8a18c8-2eb7-46c4-9bd4-e638bdebbfbf"},{"text":"2、SQL","level":3,"id":"ca5a15d0-863d-433a-afd1-6cfeed10e7cf"},{"text":"五、数据类型","level":2,"id":"b5ffa07d-b58b-4eac-ae8e-8cc4664065ac"},{"text":"六、脚本示例","level":2,"id":"a91d58d6-2548-4847-b730-15b1829a6ed2"}]},"__N_SSG":true}