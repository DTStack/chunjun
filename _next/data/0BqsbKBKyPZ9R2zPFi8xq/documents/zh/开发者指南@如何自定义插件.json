{"pageProps":{"content":"\n              <a id=\"如何自定义插件\" style='display: block; height: 35px;'></a>\n              <h2>\n                如何自定义插件\n              </h2>\n            <p>本文面向 ChunJun 插件开发人员，尝试通过一个开发者的角度尽可能全面地阐述一个 ChunJun 插件所经历的过程，同时消除开发者的困惑，快速上手插件开发。</p>\n<p>从数据流的角度来看 ChunJun，可以理解为不同数据源的数据流通过对应的 ChunJun 插件处理，变成符合 ChunJun 数据规范的数据流；脏数据的处理可以理解为脏水流通过污水处理厂，变成符合标准，可以使用的水流，而对不能处理的水流收集起来。</p>\n<p>插件开发不需要关注任务具体如何调度，只需要关注关键问题：</p>\n<ol>\n<li>数据源本身读写数据的正确性；</li>\n<li>如何合理且正确地使用框架；</li>\n<li>配置文件的规范，每个插件都应有对应的配置文件；</li>\n</ol>\n<p>每个插件应当有以下目录：</p>\n<ol>\n<li>conf：存放插件配置类的包。</li>\n<li>converter：存放插件数据类型转换规则类的包。</li>\n<li>source：存放插件数据源读取逻辑有关类的包。</li>\n<li>sink：存放插件数据源写入逻辑有关类的包。</li>\n<li>table：存放插件数据源 sql 模式有关类的包。</li>\n<li>util：存放插件工具类的包，chunjun 已经封装了一些常用工具类在 chunjun-core 模块中，如果还需编写插件工具类的请放在该插件目录中的 util 包。</li>\n</ol>\n\n              <a id=\"一. Debug 调试\" style='display: block; height: 35px;'></a>\n              <h3>\n                一. Debug 调试\n              </h3>\n            \n              <a id=\"（1）本地调试\" style='display: block; height: 35px;'></a>\n              <h4>\n                （1）本地调试\n              </h4>\n            <p>在 chunjun-local-test 模块中，官方已经写好了本地测试的 LocalTest 类，只需更改脚本文件路径，在代码处打上断点即可调试。</p>\n<p><img src=\"/chunjun/doc/contribute/image-20220614171917692.png\" alt=\"image-20220614171917692\"></p>\n\n              <a id=\"（2）远程调试\" style='display: block; height: 35px;'></a>\n              <h4>\n                （2）远程调试\n              </h4>\n            <p>如果需要远程调试，那么需要在 flink-conf.yaml 中增加 Flink 的远程调试配置，然后在 idea 中配置”JVM Remote“，在代码块中打断点（这种方法还能调试 Flink 本身的代码）</p>\n<pre><code class=\"language-shell\">env<span class=\"hljs-selector-class\">.java</span><span class=\"hljs-selector-class\">.opts</span><span class=\"hljs-selector-class\">.jobmanager</span>: -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=<span class=\"hljs-number\">5005</span>\n\nenv<span class=\"hljs-selector-class\">.java</span><span class=\"hljs-selector-class\">.opts</span><span class=\"hljs-selector-class\">.taskmanager</span>: -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=<span class=\"hljs-number\">5006</span>\n</code></pre>\n<p>只需要修改标记的这两个地方，如果是 HA 集群，需要根据日志修改<strong>怎么看日志，怎么修改，自行查资料</strong>。</p>\n<p><img src=\"/chunjun/doc/contribute/image-20220614172338108.png\" alt=\"image-20220614172338108\"></p>\n<p>至此，任务 idea 调试流程就这些内容。</p>\n\n              <a id=\"二. sync(json)插件\" style='display: block; height: 35px;'></a>\n              <h3>\n                二. sync(json)插件\n              </h3>\n            <p>以 Stream 插件为例：</p>\n\n              <a id=\"(1) reader\" style='display: block; height: 35px;'></a>\n              <h4>\n                (1) reader\n              </h4>\n            <p>插件数据源读取逻辑需要继承 BaseRichInputFormat 类，BaseRichInputFormat 是具体的输入数据的操作，包括 open、nextRecord、close，每个插件具体操作自己的数据，InputFormat 公共内容都在 BaseRichInputFormat，不要随意修改。</p>\n<p>创建 StreamInputFormat 类继承 BaseRichInputFormat 类，重写其中的必要方法。</p>\n<pre><code class=\"language-java\"><span class=\"hljs-selector-tag\">public</span> <span class=\"hljs-selector-tag\">class</span> <span class=\"hljs-selector-tag\">StreamInputFormat</span> <span class=\"hljs-selector-tag\">extends</span> <span class=\"hljs-selector-tag\">BaseRichInputFormat</span> {\n    <span class=\"hljs-comment\">//创建数据分片</span>\n    <span class=\"hljs-variable\">@Override</span>\n    public InputSplit[] <span class=\"hljs-built_in\">createInputSplitsInternal</span>(int minNumSplits) {......}\n    <span class=\"hljs-comment\">//打开数据连接</span>\n    <span class=\"hljs-variable\">@Override</span>\n    public void <span class=\"hljs-built_in\">openInternal</span>(InputSplit inputSplit) {......}\n    <span class=\"hljs-comment\">//读取一条数据</span>\n     <span class=\"hljs-variable\">@Override</span>\n    public RowData <span class=\"hljs-built_in\">nextRecordInternal</span>(RowData rowData) throws ReadRecordException {......}\n    <span class=\"hljs-comment\">//判断数据是否读取完毕</span>\n    <span class=\"hljs-variable\">@Override</span>\n    public boolean <span class=\"hljs-built_in\">reachedEnd</span>() {......}\n    <span class=\"hljs-comment\">//关闭数据连接</span>\n    <span class=\"hljs-variable\">@Override</span>\n    protected void <span class=\"hljs-built_in\">closeInternal</span>() {......}\n}\n</code></pre>\n<p>StreamInputFormat 类是通过 StreamInputFormatBuilder 类构建的。</p>\n<pre><code class=\"language-java\">public <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">StreamInputFormatBuilder</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BaseRichInputFormatBuilder&lt;StreamInputFormat&gt;</span>  </span>{\n\n    <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> <span class=\"hljs-type\">StreamInputFormat</span> format;\n\n    public <span class=\"hljs-type\">StreamInputFormatBuilder</span>() {\n        <span class=\"hljs-keyword\">super</span>.format = format = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">StreamInputFormat</span>();\n    }\n    <span class=\"hljs-comment\">//检查inputformat配置</span>\n    <span class=\"hljs-meta\">@Override</span>\n    <span class=\"hljs-keyword\">protected</span> void checkFormat() {......}\n}\n</code></pre>\n<p>创建 StreamSourceFactory 继承 SourceFactory 类</p>\n<pre><code class=\"language-java\">public <span class=\"hljs-keyword\">class</span> StreamSourceFactory extends SourceFactory {\n    <span class=\"hljs-keyword\">private</span> final StreamConf streamConf;\n\n    public <span class=\"hljs-constructor\">StreamSourceFactory(SyncConf <span class=\"hljs-params\">config</span>, StreamExecutionEnvironment <span class=\"hljs-params\">env</span>)</span> {......}\n\n    <span class=\"hljs-comment\">//构建数据流读取对象</span>\n    @Override\n    public DataStream&lt;RowData&gt; create<span class=\"hljs-constructor\">Source()</span> {\n        StreamInputFormatBuilder builder = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamInputFormatBuilder()</span>;\n        builder.set<span class=\"hljs-constructor\">StreamConf(<span class=\"hljs-params\">streamConf</span>)</span>;\n        AbstractRowConverter rowConverter;\n        <span class=\"hljs-keyword\">if</span> (useAbstractBaseColumn) {\n            rowConverter = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamColumnConverter(<span class=\"hljs-params\">streamConf</span>)</span>;\n        } <span class=\"hljs-keyword\">else</span> {\n            check<span class=\"hljs-constructor\">Constant(<span class=\"hljs-params\">streamConf</span>)</span>;\n            final RowType rowType =\n                    <span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">TableUtil</span>.</span></span>create<span class=\"hljs-constructor\">RowType(<span class=\"hljs-params\">streamConf</span>.<span class=\"hljs-params\">getColumn</span>()</span>, get<span class=\"hljs-constructor\">RawTypeConverter()</span>);\n            rowConverter = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamRowConverter(<span class=\"hljs-params\">rowType</span>)</span>;\n        }\n        builder.set<span class=\"hljs-constructor\">RowConverter(<span class=\"hljs-params\">rowConverter</span>, <span class=\"hljs-params\">useAbstractBaseColumn</span>)</span>;\n\n        return create<span class=\"hljs-constructor\">Input(<span class=\"hljs-params\">builder</span>.<span class=\"hljs-params\">finish</span>()</span>);\n    }\n    <span class=\"hljs-comment\">//获取数据类型转换连接器，数据类型转换关系的实现</span>\n    @Override\n    public RawTypeConverter get<span class=\"hljs-constructor\">RawTypeConverter()</span> {\n        return StreamRawTypeConverter::apply;\n    }\n}\n</code></pre>\n<p>StreamColumnConverter 继承 AbstractRowConverter 类 是数据类型转换的具体实现，其中的方法参看源码。</p>\n<p>接下来从作业执行角度阐述上述类之间的执行关系。</p>\n<ol>\n<li><p>com.dtstack.chunjun.Main 入口类，通过判断启动参数来决定启动何种作业。</p>\n<p><img src=\"/chunjun/doc/contribute/image-20220614143347037.png\" alt=\"image-20220614143347037\"></p>\n</li>\n<li><p>解析参数生成 SyncConf 对象，配置执行环境。</p>\n</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614144650798.png\" alt=\"image-20220614144650798\"></p>\n<ol start=\"3\">\n<li>.将上面解析生成的 SyncConf，然后通过反射加载具体的插件调用 createSource 方法生成 DataStream</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614145127874.png\" alt=\"image-20220614145127874\"></p>\n<ol start=\"4\">\n<li>createSource 方法中会构建 inputformat 对象，然后调用 createInput 方法，将 inputformat 对象封装至 DtInputFormatSourceFunction 中。</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614145839069.png\" alt=\"image-20220614145839069\"></p>\n<ol start=\"5\">\n<li>DtInputFormatSourceFunction 类中会调用 inputformat 对象中的逻辑去读取数据，inputformat 中的 nextRecordInternal 方法读数据时，会对每条数据进行数据类型转换。</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614150742626.png\" alt=\"image-20220614150742626\"></p>\n<ol start=\"6\">\n<li><p>数据类型转换，flink 自己内部有一套自己的数据类型，用来和外部系统进行交互。交互过程分为：将外部系统数据按照定义的类型读入到 flink 内部、将外部数据转换成 flink 内部类型、将内部类型进行转换写到外部系统。所以每个插件需要有一套类型转换机制来满足数据交互的需求。</p>\n</li>\n<li><p>将外部数据转换成 flink 内部类，每个插件的转换方式都不同。</p>\n</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614151300210.png\" alt=\"image-20220614151300210\"></p>\n\n              <a id=\"(2) writer\" style='display: block; height: 35px;'></a>\n              <h4>\n                (2) writer\n              </h4>\n            <p>插件数据源读取逻辑需要继承 BaseRichOutputFormat 类，BaseRichOutputFormat 是具体的输入数据的操作，包括 open、writeRecord、close，每个插件具体操作自己的数据，OutputFormat 公共内容都在 BaseRichOutputFormat，不要随意修改。</p>\n<p>创建 StreamOutputformat 类继承 BaseRichOutputformat 类，重写其中的必要方法。</p>\n<pre><code class=\"language-java\">public class <span class=\"hljs-type\">StreamOutputFormat</span> extends <span class=\"hljs-type\">BaseRichOutputFormat</span> {\n    //打开资源\n    @<span class=\"hljs-type\">Override</span>\n    protected <span class=\"hljs-type\">void</span> openInternal(<span class=\"hljs-type\">int</span> taskNumber, <span class=\"hljs-type\">int</span> numTasks) <span class=\"hljs-meta\">{......}</span>\n    //写出单条数据\n    @<span class=\"hljs-type\">Override</span>\n    protected <span class=\"hljs-type\">void</span> writeSingleRecordInternal(<span class=\"hljs-type\">RowData</span> rowData) throws <span class=\"hljs-type\">WriteRecordException</span> <span class=\"hljs-meta\">{......}</span>\n    //写出多条数据\n    @<span class=\"hljs-type\">Override</span>\n    protected <span class=\"hljs-type\">void</span> writeMultipleRecordsInternal() throws <span class=\"hljs-type\">Exception</span> <span class=\"hljs-meta\">{......}</span>\n    //关闭资源\n    @<span class=\"hljs-type\">Override</span>\n    protected <span class=\"hljs-type\">void</span> closeInternal() <span class=\"hljs-meta\">{......}</span>\n}\n</code></pre>\n<p>StreamOutputFormat 类是通过 StreamOutputFormatBuilder 构建的</p>\n<pre><code class=\"language-java\">public <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">StreamOutputFormatBuilder</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BaseRichOutputFormatBuilder</span> </span>{\n\n    <span class=\"hljs-keyword\">private</span> <span class=\"hljs-type\">StreamOutputFormat</span> format;\n\n    public <span class=\"hljs-type\">StreamOutputFormatBuilder</span>() {\n        <span class=\"hljs-keyword\">super</span>.format = format = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">StreamOutputFormat</span>();\n    }\n    <span class=\"hljs-comment\">//检查Outputformat配置</span>\n    <span class=\"hljs-meta\">@Override</span>\n    <span class=\"hljs-keyword\">protected</span> void checkFormat() {......}\n}\n</code></pre>\n<p>创建 StreamSinkFactory 类继承 SinkFactory 类</p>\n<pre><code class=\"language-java\">public <span class=\"hljs-keyword\">class</span> StreamSinkFactory extends SinkFactory {\n\n    <span class=\"hljs-keyword\">private</span> final StreamConf streamConf;\n\n    public <span class=\"hljs-constructor\">StreamSinkFactory(SyncConf <span class=\"hljs-params\">config</span>)</span> {......}\n\n    <span class=\"hljs-comment\">//构建数据输出流对象</span>\n    @Override\n    public DataStreamSink&lt;RowData&gt; create<span class=\"hljs-constructor\">Sink(DataStream&lt;RowData&gt; <span class=\"hljs-params\">dataSet</span>)</span> {\n        StreamOutputFormatBuilder builder = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamOutputFormatBuilder()</span>;\n        builder.set<span class=\"hljs-constructor\">StreamConf(<span class=\"hljs-params\">streamConf</span>)</span>;\n        AbstractRowConverter converter;\n        <span class=\"hljs-keyword\">if</span> (useAbstractBaseColumn) {\n            converter = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamColumnConverter(<span class=\"hljs-params\">streamConf</span>)</span>;\n        } <span class=\"hljs-keyword\">else</span> {\n            final RowType rowType =\n                    <span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">TableUtil</span>.</span></span>create<span class=\"hljs-constructor\">RowType(<span class=\"hljs-params\">streamConf</span>.<span class=\"hljs-params\">getColumn</span>()</span>, get<span class=\"hljs-constructor\">RawTypeConverter()</span>);\n            converter = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">StreamRowConverter(<span class=\"hljs-params\">rowType</span>)</span>;\n        }\n\n        builder.set<span class=\"hljs-constructor\">RowConverter(<span class=\"hljs-params\">converter</span>, <span class=\"hljs-params\">useAbstractBaseColumn</span>)</span>;\n        return create<span class=\"hljs-constructor\">Output(<span class=\"hljs-params\">dataSet</span>, <span class=\"hljs-params\">builder</span>.<span class=\"hljs-params\">finish</span>()</span>);\n    }\n    <span class=\"hljs-comment\">//获取数据类型转换连接器，数据类型转换关系的实现</span>\n    @Override\n    public RawTypeConverter get<span class=\"hljs-constructor\">RawTypeConverter()</span> {\n        return StreamRawTypeConverter::apply;\n    }\n}\n</code></pre>\n<p>接下来从作业执行角度阐述上述类之间的执行关系，在阐述 reader 插件执行步骤第三步时，通过反射加载具体的插件调用 createSource 方法生成 DataStream，同理，在生成 DataStream 后，writer 插件也是通过反射加载调用 createSink 方法生成 DataStreamSink 的。</p>\n<p><img src=\"/chunjun/doc/contribute/image-20220616102414067.png\" alt=\"image-20220616102414067\"></p>\n<ol>\n<li>createSink 方法中会构建 outputformat 对象，然后调用 createoutput 方法，将 outputformat 对象封装至 DtOutputFormatSinkFunction 中。</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220616102856402.png\" alt=\"image-20220616102856402\"></p>\n<ol start=\"2\">\n<li>DtOutputFormatSinkFunction 类中会调用 outputformat 对象中的逻辑去写入数据，outputformat 中的 writeSingleRecordInternal 方法写入数据时，会对每条数据进行数据类型转换。</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220616103241458.png\" alt=\"image-20220616103241458\"></p>\n\n              <a id=\"三. sql 插件\" style='display: block; height: 35px;'></a>\n              <h3>\n                三. sql 插件\n              </h3>\n            <p><strong>Flink SQL Connetor 详细设计文档参见</strong><a href=\"https://cwiki.apache.org/confluence/display/FLINK/FLIP-95%3A+New+TableSource+and+TableSink+interfaces\">FLIP-95</a></p>\n<p>Flink SQL Connector 的架构简图如下所示:</p>\n<img src=\"/chunjun/doc/contribute/195230-11f4ee6bc7e788c7.webp\" alt=\"195230-11f4ee6bc7e788c7.webp\" style=\"zoom:67%;\" />\n\n<p>动态表一直都是 Flink SQL 流批一体化的重要概念，也是上述架构中 Planning 阶段的核心。而自定义 Connector 的主要工作就是实现基于动态表的 Source/Sink，还包括上游产生它的工厂，以及下游在 Runtime 阶段实际执行 Source/Sink 逻辑的 RuntimeProvider。</p>\n<p>DynamicTableFactory 需要具备以下功能：</p>\n<ul>\n<li>定义与校验建表时传入的各项参数；</li>\n<li>获取表的元数据；</li>\n<li>定义读写数据时的编码/解码格式（非必需）；</li>\n<li>创建可用的 DynamicTable[Source/Sink]实例。</li>\n</ul>\n<p>DynamicTableSourceFactory：源表工厂，里面包含从 source 来的表(如：源表 kafka)，从 lookup 来的表(如：维表 mysql)</p>\n<p>DynamicTableSinkFactory：结果表工厂，里面包含从 sink 来的表(如：结果表 mysql)</p>\n<p>DynamicTableSource：生成需要读取数据的 RichSourceFunction(面向流)\\RichInputFormat(面向批，也可以用于流)，实现 ScanTableSource 即可得到。生成需要读取数据的 TableFunction(全量)\\AsyncTableFunction(lru)，实现 LookupTableSource 即可。并被包装成 Provider。</p>\n<p>DynamicTableSink：生成需要写出数据的 RichSinkFunction(面向流)\\RichOutputFormat(面向批，也可以用于流)。并被包装成 Provider。</p>\n<p>如果一个插件需要 source 端包含源表和维表,则实现 ScanTableSource 和 LookupTableSource 接口</p>\n<p>如果一个插件需要 sink 端，则实现 DynamicTableSink 接口</p>\n<p>实现了 DynamicTable[Source/Sink]Factory 接口的工厂类如下所示。</p>\n<pre><code class=\"language-java\"><span class=\"hljs-selector-tag\">public</span> <span class=\"hljs-selector-tag\">class</span> <span class=\"hljs-selector-tag\">StreamDynamicTableFactory</span> <span class=\"hljs-selector-tag\">implements</span> <span class=\"hljs-selector-tag\">DynamicTableSourceFactory</span>, <span class=\"hljs-selector-tag\">DynamicTableSinkFactory</span> {\n  <span class=\"hljs-comment\">//创建DynamicTableSource</span>\n  <span class=\"hljs-variable\">@Override</span>\n  public DynamicTableSource <span class=\"hljs-built_in\">createDynamicTableSource</span>(Context context) { }\n  <span class=\"hljs-comment\">//创建DynamicTableSink</span>\n  <span class=\"hljs-variable\">@Override</span>\n  public DynamicTableSink <span class=\"hljs-built_in\">createDynamicTableSink</span>(Context context) { }\n  <span class=\"hljs-comment\">//connector唯一标识符</span>\n  <span class=\"hljs-variable\">@Override</span>\n  public String <span class=\"hljs-built_in\">factoryIdentifier</span>() { }\n  <span class=\"hljs-comment\">//必选参数设置</span>\n  <span class=\"hljs-variable\">@Override</span>\n  public Set&lt;ConfigOption&lt;?&gt;&gt; <span class=\"hljs-built_in\">requiredOptions</span>() { }\n  <span class=\"hljs-comment\">//可选参数设置</span>\n  <span class=\"hljs-variable\">@Override</span>\n  public Set&lt;ConfigOption&lt;?&gt;&gt; <span class=\"hljs-built_in\">optionalOptions</span>() { }\n}\n</code></pre>\n<ol>\n<li>根据 Connector 特性是否只用到 source、sink，实现对应的接口，这里以 stream 为例：既可以作为源表、又可以作为结果表，所以实现如下：</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614152751238.png\" alt=\"image-20220614152751238\"></p>\n<ol start=\"2\">\n<li>实现 createDynamicTableSource 方法用来创建 DynamicTableSource(ScanTableSource)，在创建之前，我们可以利用内置的 TableFactoryHelper 工具类来校验传入的参数，当然也可以自己编写校验逻辑。另外，通过关联的上下文对象还能获取到表的元数据。</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614152928836.png\" alt=\"image-20220614152928836\"></p>\n<ol start=\"3\">\n<li><p>创建 StreamDynamicTableSource 类，目前 stream 实现了 ScanTableSource，实现 getScanRuntimeProvider 方法，用来创建 DtInputFormatSourceFunction(并创建 StreamInputFormat 包含在 DtInputFormatSourceFunction 中)</p>\n<p>DtInputFormatSourceFunction：是所有 InputFormat 的包装类，里面实现类 2pc 等功能，不要随意修改。</p>\n</li>\n</ol>\n<p><img src=\"/chunjun/doc/contribute/image-20220614153545215.png\" alt=\"image-20220614153545215\"></p>\n<ol start=\"4\">\n<li><p>最后创建 StreamInputFormat，用来对数据的操作包括(open、writeRecord、close 方法)，公共的内容已经抽取到了 BaseRichInputFormat 中，是所有 OutputFormat 的公共类，不要随意修改。</p>\n</li>\n<li><p>sink 类似。</p>\n</li>\n<li><p>插件也可按需求实现 LookupTableSource 类，以 jdbc 插件为例，实现 getLookupRuntimeProvider 方法，创建 JdbcLruTableFunction/JdbcAllTableFunction，</p>\n<pre><code class=\"language-tex\">维表，支持全量和异步方式\n<span class=\"hljs-section\">全量缓存:将维表数据全部加载到内存中，建议数据量大不使用。</span>\n<span class=\"hljs-section\">异步缓存:使用异步方式查询数据，并将查询到的数据使用lru缓存到内存中，建议数据量大使用。</span>\n</code></pre>\n<p><img src=\"/chunjun/doc/contribute/image-20220616112115980.png\" alt=\"images\"></p>\n</li>\n<li><p>JdbcLruTableFunction 继承 AbstractLruTableFunction，重写其必要方法，JdbcAllTableFunction 继承 AbstractAllTableFunction，具体逻辑实现参考源码。</p>\n</li>\n<li><p>Flink SQL 采用 SPI 机制来发现与加载表工厂类。所以最后不要忘了 classpath 的 META-INF/services 目录下创建一个名为<code>org.apache.flink.table.factories.Factory</code>的文件，并写入我们自定义的工厂类的全限定名，如：com.dtstack.chunjun.connector.stream.table.StreamDynamicTableFactory</p>\n</li>\n</ol>\n\n              <a id=\"四. 插件打包\" style='display: block; height: 35px;'></a>\n              <h3>\n                四. 插件打包\n              </h3>\n            <p>进入项目根目录，使用 maven 打包，有关打包配置请参考其他插件的 pom 文件。</p>\n<pre><code class=\"language-sh\">mvn clean <span class=\"hljs-keyword\">package</span> <span class=\"hljs-title\">-DskipTests</span>\n</code></pre>\n<p>打包之前注意代码格式，在项目根目录执行以下命令格式化代码。</p>\n<pre><code class=\"language-shell\"><span class=\"hljs-keyword\">mvn</span> spotless:apply\n</code></pre>\n<p>打包结束后，项目根目录下会产生 chunjun-dist 目录，如果没意外的话，您开发的插件会在 connetor 目录下，之后就可以提交开发平台测试啦！</p>\n","tree":[{"label":"ChunJun通用配置详解","category":"file"},{"label":"快速开始","category":"file"},{"label":"ChunJun拓展数据格式","children":[{"label":"protobuf-x","path":"protobuf-x","category":"file"}],"category":"dir"},{"label":"ChunJun连接器","children":[{"label":"binlog","category":"dir","children":[{"label":"binlog-source","path":"binlog-source","category":"file"}]},{"label":"clickhouse","category":"dir","children":[{"label":"clickhouse-lookup","path":"clickhouse-lookup","category":"file"},{"label":"clickhouse-sink","path":"clickhouse-sink","category":"file"},{"label":"clickhouse-source","path":"clickhouse-source","category":"file"}]},{"label":"db2","category":"dir","children":[{"label":"db2-lookup","path":"db2-lookup","category":"file"},{"label":"db2-sink","path":"db2-sink","category":"file"},{"label":"db2-source","path":"db2-source","category":"file"}]},{"label":"dm","category":"dir","children":[{"label":"dm-sink","path":"dm-sink","category":"file"},{"label":"dm-source","path":"dm-source","category":"file"}]},{"label":"doris","category":"dir","children":[{"label":"dorisbatch-sink","path":"dorisbatch-sink","category":"file"}]},{"label":"elasticsearch","category":"dir","children":[{"label":"es7-lookup","path":"es7-lookup","category":"file"},{"label":"es7-sink","path":"es7-sink","category":"file"},{"label":"es7-source","path":"es7-source","category":"file"}]},{"label":"gbase","category":"dir","children":[{"label":"gbase-lookup","path":"gbase-lookup","category":"file"},{"label":"gbase-sink","path":"gbase-sink","category":"file"},{"label":"gbase-source","path":"gbase-source","category":"file"}]},{"label":"greenplum","category":"dir","children":[{"label":"greenplum-sink","path":"greenplum-sink","category":"file"},{"label":"greenplum-source","path":"greenplum-source","category":"file"}]},{"label":"hbase","category":"dir","children":[{"label":"hbase-lookup","path":"hbase-lookup","category":"file"},{"label":"hbase-sink","path":"hbase-sink","category":"file"},{"label":"hbase-source","path":"hbase-source","category":"file"}]},{"label":"hdfs","category":"dir","children":[{"label":"hdfs-sink","path":"hdfs-sink","category":"file"},{"label":"hdfs-source","path":"hdfs-source","category":"file"}]},{"label":"hive","category":"dir","children":[{"label":"hive-lookup","path":"hive-lookup","category":"file"},{"label":"hive-sink","path":"hive-sink","category":"file"}]},{"label":"influxdb","category":"dir","children":[{"label":"influxdb-sink","path":"influxdb-sink","category":"file"},{"label":"influxdb-source","path":"influxdb-source","category":"file"}]},{"label":"kafka","category":"dir","children":[{"label":"kafka-sink","path":"kafka-sink","category":"file"},{"label":"kafka-source","path":"kafka-source","category":"file"}]},{"label":"kingbase","category":"dir","children":[{"label":"kingbase-sink","path":"kingbase-sink","category":"file"},{"label":"kingbase-source","path":"kingbase-source","category":"file"}]},{"label":"kudu","category":"dir","children":[{"label":"kudu-lookup","path":"kudu-lookup","category":"file"},{"label":"kudu-sink","path":"kudu-sink","category":"file"},{"label":"kudu-source","path":"kudu-source","category":"file"}]},{"label":"logminer","category":"dir","children":[{"label":"LogMiner-source","path":"LogMiner-source","category":"file"},{"label":"LogMiner原理","path":"LogMiner原理","category":"file"},{"label":"LogMiner配置","path":"LogMiner配置","category":"file"}]},{"label":"mongodb","category":"dir","children":[{"label":"mongodb-lookup","path":"mongodb-lookup","category":"file"},{"label":"mongodb-sink","path":"mongodb-sink","category":"file"},{"label":"mongodb-source","path":"mongodb-source","category":"file"}]},{"label":"mysql","category":"dir","children":[{"label":"mysql-lookup","path":"mysql-lookup","category":"file"},{"label":"mysql-sink","path":"mysql-sink","category":"file"},{"label":"mysql-source","path":"mysql-source","category":"file"}]},{"label":"oracle","category":"dir","children":[{"label":"oracle-lookup","path":"oracle-lookup","category":"file"},{"label":"oracle-sink","path":"oracle-sink","category":"file"},{"label":"oracle-source","path":"oracle-source","category":"file"}]},{"label":"pgwal","category":"dir","children":[{"label":"Postgres-CDC","path":"Postgres-CDC","category":"file"}]},{"label":"postgresql","category":"dir","children":[{"label":"postgres-lookup","path":"postgres-lookup","category":"file"},{"label":"postgres-sink","path":"postgres-sink","category":"file"},{"label":"postgres-source","path":"postgres-source","category":"file"}]},{"label":"rocketmq","category":"dir","children":[{"label":"rocketmq-source","path":"rocketmq-source","category":"file"}]},{"label":"saphana","category":"dir","children":[{"label":"saphana-sink","path":"saphana-sink","category":"file"},{"label":"saphana-source","path":"saphana-source","category":"file"}]},{"label":"sqlserver","category":"dir","children":[{"label":"sqlserver-lookup","path":"sqlserver-lookup","category":"file"},{"label":"sqlserver-sink","path":"sqlserver-sink","category":"file"},{"label":"sqlserver-source","path":"sqlserver-source","category":"file"}]},{"label":"sqlservercdc","category":"dir","children":[{"label":"SqlServer CDC实时采集原理","path":"SqlServer CDC实时采集原理","category":"file"},{"label":"SqlServer配置CDC","path":"SqlServer配置CDC","category":"file"},{"label":"SqlserverCDC-source","path":"SqlserverCDC-source","category":"file"}]}],"category":"dir"},{"label":"开发者指南","children":[{"label":"如何提交一个优秀的PR","path":"如何提交一个优秀的PR","category":"file"},{"label":"如何自定义插件","path":"如何自定义插件","category":"file"}],"category":"dir"},{"label":"拓展功能","children":[{"label":"增量同步介绍","path":"增量同步介绍","category":"file"},{"label":"断点续传介绍","path":"断点续传介绍","category":"file"},{"label":"脏数据插件设计","path":"脏数据插件设计","category":"file"}],"category":"dir"}],"toc":[{"text":"如何自定义插件","level":2,"id":"ebc8fffe-3a8c-4af7-a07a-94d988220337"},{"text":"一. Debug 调试","level":3,"id":"6a26d610-64e0-421d-ac3b-e208b511e154"},{"text":"（1）本地调试","level":4,"id":"2374deb6-f755-45c7-9e17-30a0e46e7639"},{"text":"（2）远程调试","level":4,"id":"77edd5b0-efa8-4a92-aaf4-af6a93d2b021"},{"text":"二. sync(json)插件","level":3,"id":"ad482ec9-f7f5-43a6-8efb-9e9372408d71"},{"text":"(1) reader","level":4,"id":"7b19cda1-2e13-434f-8bc6-9177544e19db"},{"text":"(2) writer","level":4,"id":"feb89b6a-25f8-49d8-899e-27bf489cf225"},{"text":"三. sql 插件","level":3,"id":"4bf4b474-d95f-462e-bb51-e88b1c8235a2"},{"text":"四. 插件打包","level":3,"id":"dba89197-a0e6-4bef-bac3-dc30c35bc833"}]},"__N_SSG":true}