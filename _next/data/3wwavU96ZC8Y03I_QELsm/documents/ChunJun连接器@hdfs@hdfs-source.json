{"pageProps":{"content":"\n              <a id=\"HDFS Source\" style='display: block; height: 35px;'></a>\n              <h1>\n                HDFS Source\n              </h1>\n            \n              <a id=\"一、介绍\" style='display: block; height: 35px;'></a>\n              <h2>\n                一、介绍\n              </h2>\n            <p>HDFS插件支持直接从配置的HDFS路径上读取及写入TextFile、Orc、Parquet类型的文件，一般配合HIve表使用。如：读取Hive表某分区下所有数据，实质是读取Hive表对应分区的HDFS路径下的数据文件；将数据写入Hive表某分区，实质是直接将数据文件写入到对应分区的HDFS路径下；HDFS插件不会对Hive表进行任何DDL操作。</p>\n<p>HDFS Source在checkpoint时不会保存读取文件的offset，因此不支持续跑。</p>\n\n              <a id=\"二、支持版本\" style='display: block; height: 35px;'></a>\n              <h2>\n                二、支持版本\n              </h2>\n            <p>Hadoop 2.x、Hadoop 3.x</p>\n\n              <a id=\"三、插件名称\" style='display: block; height: 35px;'></a>\n              <h2>\n                三、插件名称\n              </h2>\n            <table>\n<thead>\n<tr>\n<th>Sync</th>\n<th>hdfssource、hdfsreader</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SQL</td>\n<td>hdfs-x</td>\n</tr>\n</tbody></table>\n\n              <a id=\"四、参数说明\" style='display: block; height: 35px;'></a>\n              <h2>\n                四、参数说明\n              </h2>\n            \n              <a id=\"1、Sync\" style='display: block; height: 35px;'></a>\n              <h3>\n                1、Sync\n              </h3>\n            <ul>\n<li><p><strong>path</strong></p>\n<ul>\n<li>描述：读取的数据文件路径 path+filename</li>\n<li>必选：是</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>fileName</strong></p>\n<ul>\n<li>描述：数据文件目录名称</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：无</li>\n<li>注意：不为空，则hdfs读取的路径为 path+filename<br /></li>\n</ul>\n</li>\n<li><p><strong>fileType</strong></p>\n<ul>\n<li>描述：文件的类型，目前只支持用户配置为<code>text</code>、<code>orc</code>、<code>parquet</code><ul>\n<li>text：textfile文件格式</li>\n<li>orc：orcfile文件格式</li>\n<li>parquet：parquet文件格式</li>\n</ul>\n</li>\n<li>必选：是</li>\n<li>参数类型：string</li>\n<li>默认值：text<br /></li>\n</ul>\n</li>\n<li><p><strong>defaultFS</strong></p>\n<ul>\n<li>描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000</li>\n<li>必选：是</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>column</strong></p>\n<ul>\n<li>描述：需要读取的字段</li>\n<li>注意：不支持*格式</li>\n<li>格式：</li>\n</ul>\n<pre><code class=\"language-text\">  <span class=\"hljs-attr\">&quot;column&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span><span class=\"hljs-punctuation\">{</span>\n      <span class=\"hljs-attr\">&quot;name&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;col&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;type&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;string&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;index&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">1</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;isPart&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\"><span class=\"hljs-keyword\">false</span></span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;format&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;yyyy-MM-dd hh:mm:ss&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;value&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;value&quot;</span>\n    <span class=\"hljs-punctuation\">}</span><span class=\"hljs-punctuation\">]</span>\n</code></pre>\n<ul>\n<li>属性说明:<ul>\n<li>name：必选，字段名称</li>\n<li>type：必选，字段类型，需要和数据文件中实际的字段类型匹配</li>\n<li>index：非必选，字段在所有字段中的位置索引，从0开始计算，默认为-1，按照数组顺序依次读取，配置后读取指定字段列</li>\n<li>isPart：非必选，是否是分区字段，如果是分区字段，会自动从path上截取分区赋值，默认为fale</li>\n<li>format：非必选，按照指定格式，格式化日期</li>\n<li>value：非必选，常量字段，将value的值作为常量列返回</li>\n</ul>\n</li>\n<li>必选：是</li>\n<li>参数类型：数组</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>hadoopConfig</strong></p>\n<ul>\n<li>描述：集群HA模式时需要填写的core-site.xml及hdfs-site.xml中的配置，开启kerberos时包含kerberos相关配置</li>\n<li>必选：否</li>\n<li>参数类型：Map&lt;String, Object&gt;</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>filterRegex</strong></p>\n<ul>\n<li>描述：文件正则表达式,读取匹配到的文件</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>fieldDelimiter</strong></p>\n<ul>\n<li>描述：<code>fileType</code>为<code>text</code>时字段的分隔符</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：<code>\\001</code><br /></li>\n</ul>\n</li>\n<li><p><strong>encoding</strong></p>\n<ul>\n<li>描述：<code>fileType</code>为<code>text</code>时字段的字符编码</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：<code>UTF-8</code></li>\n</ul>\n</li>\n</ul>\n\n              <a id=\"2、SQL\" style='display: block; height: 35px;'></a>\n              <h3>\n                2、SQL\n              </h3>\n            <ul>\n<li><p><strong>path</strong></p>\n<ul>\n<li>描述：读取的数据文件路径</li>\n<li>必选：是</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>file-type</strong></p>\n<ul>\n<li>描述：文件的类型，目前只支持用户配置为<code>text</code>、<code>orc</code>、<code>parquet</code><ul>\n<li>text：textfile文件格式</li>\n<li>orc：orcfile文件格式</li>\n<li>parquet：parquet文件格式</li>\n</ul>\n</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>default-fs</strong></p>\n<ul>\n<li>描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000</li>\n<li>必选：是</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>column</strong></p>\n<ul>\n<li>描述：需要读取的字段</li>\n<li>注意：不支持*格式</li>\n<li>格式：</li>\n</ul>\n<pre><code class=\"language-text\">  <span class=\"hljs-attr\">&quot;column&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span><span class=\"hljs-punctuation\">{</span>\n      <span class=\"hljs-attr\">&quot;name&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;col&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;type&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;string&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;index&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">1</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;isPart&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\"><span class=\"hljs-keyword\">false</span></span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;format&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;yyyy-MM-dd hh:mm:ss&quot;</span><span class=\"hljs-punctuation\">,</span>\n      <span class=\"hljs-attr\">&quot;value&quot;</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;value&quot;</span>\n    <span class=\"hljs-punctuation\">}</span><span class=\"hljs-punctuation\">]</span>\n</code></pre>\n<ul>\n<li>属性说明:<ul>\n<li>name：必选，字段名称</li>\n<li>type：必选，字段类型，需要和数据文件中实际的字段类型匹配</li>\n<li>index：非必选，字段在所有字段中的位置索引，从0开始计算，默认为-1，按照数组顺序依次读取，配置后读取指定字段列</li>\n<li>isPart：非必选，是否是分区字段，如果是分区字段，会自动从path上截取分区赋值，默认为fale</li>\n<li>format：非必选，按照指定格式，格式化日期</li>\n<li>value：非必选，常量字段，将value的值作为常量列返回</li>\n</ul>\n</li>\n<li>必选：是</li>\n<li>参数类型：数组</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>hadoopConfig</strong></p>\n<ul>\n<li>描述：集群HA模式时需要填写的core-site.xml及hdfs-site.xml中的配置，开启kerberos时包含kerberos相关配置</li>\n<li>必选：否</li>\n<li>默认值：无</li>\n<li>配置方式：&#39;properties.key&#39; = &#39;value&#39;，key为hadoopConfig中的key，value为hadoopConfig中的value，如下所示：</li>\n</ul>\n<pre><code class=\"language-text\"><span class=\"hljs-attr\">&#x27;properties.hadoop.user.name&#x27;</span> = <span class=\"hljs-string\">&#x27;root&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.dfs.ha.namenodes.ns&#x27;</span> = <span class=\"hljs-string\">&#x27;nn1,nn2&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.fs.defaultFS&#x27;</span> = <span class=\"hljs-string\">&#x27;hdfs://ns&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.dfs.namenode.rpc-address.ns.nn2&#x27;</span> = <span class=\"hljs-string\">&#x27;ip:9000&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.dfs.client.failover.proxy.provider.ns&#x27;</span> = <span class=\"hljs-string\">&#x27;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.dfs.namenode.rpc-address.ns.nn1&#x27;</span> = <span class=\"hljs-string\">&#x27;ip:9000&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.dfs.nameservices&#x27;</span> = <span class=\"hljs-string\">&#x27;ns&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.fs.hdfs.impl.disable.cache&#x27;</span> = <span class=\"hljs-string\">&#x27;true&#x27;</span>,\n<span class=\"hljs-attr\">&#x27;properties.fs.hdfs.impl&#x27;</span> = <span class=\"hljs-string\">&#x27;org.apache.hadoop.hdfs.DistributedFileSystem&#x27;</span>\n</code></pre>\n</li>\n<li><p><strong>filter-regex</strong></p>\n<ul>\n<li>描述：文件正则表达式,读取匹配到的文件</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n<li><p><strong>field-delimiter</strong></p>\n<ul>\n<li>描述：<code>fileType</code>为<code>text</code>时字段的分隔符</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：<code>\\001</code><br /></li>\n</ul>\n</li>\n<li><p><strong>encoding</strong></p>\n<ul>\n<li>描述：<code>fileType</code>为<code>text</code>时字段的字符编码</li>\n<li>必选：否</li>\n<li>参数类型：string</li>\n<li>默认值：<code>UTF-8</code></li>\n</ul>\n</li>\n<li><p><strong>scan.parallelism</strong></p>\n<ul>\n<li>描述：source的并行度</li>\n<li>必选：否</li>\n<li>参数类型：String</li>\n<li>默认值：无<br /></li>\n</ul>\n</li>\n</ul>\n\n              <a id=\"五、数据类型\" style='display: block; height: 35px;'></a>\n              <h2>\n                五、数据类型\n              </h2>\n            <table>\n<thead>\n<tr>\n<th>支持</th>\n<th>BOOLEAN、TINYINT、SMALLINT、INT、BIGINT、FLOAT、DOUBLE、DECIMAL、STRING、VARCHAR、CHAR、TIMESTAMP、DATE、BINARY</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>暂不支持</td>\n<td>ARRAY、MAP、STRUCT、UNION</td>\n</tr>\n</tbody></table>\n\n              <a id=\"六、脚本示例\" style='display: block; height: 35px;'></a>\n              <h2>\n                六、脚本示例\n              </h2>\n            <p>见项目内<code>chunjun-examples</code>文件夹。</p>\n","tree":[{"label":"ChunJun通用配置详解","category":"file"},{"label":"快速开始","category":"file"},{"label":"ChunJun拓展数据格式","children":[{"label":"protobuf-x","path":"protobuf-x","category":"file"}],"category":"dir"},{"label":"ChunJun连接器","children":[{"label":"binlog","category":"dir","children":[{"label":"binlog-source","path":"binlog-source","category":"file"}]},{"label":"clickhouse","category":"dir","children":[{"label":"clickhouse-lookup","path":"clickhouse-lookup","category":"file"},{"label":"clickhouse-sink","path":"clickhouse-sink","category":"file"},{"label":"clickhouse-source","path":"clickhouse-source","category":"file"}]},{"label":"db2","category":"dir","children":[{"label":"db2-lookup","path":"db2-lookup","category":"file"},{"label":"db2-sink","path":"db2-sink","category":"file"},{"label":"db2-source","path":"db2-source","category":"file"}]},{"label":"dm","category":"dir","children":[{"label":"dm-sink","path":"dm-sink","category":"file"},{"label":"dm-source","path":"dm-source","category":"file"}]},{"label":"doris","category":"dir","children":[{"label":"dorisbatch-sink","path":"dorisbatch-sink","category":"file"}]},{"label":"elasticsearch","category":"dir","children":[{"label":"es7-lookup","path":"es7-lookup","category":"file"},{"label":"es7-sink","path":"es7-sink","category":"file"},{"label":"es7-source","path":"es7-source","category":"file"}]},{"label":"gbase","category":"dir","children":[{"label":"gbase-lookup","path":"gbase-lookup","category":"file"},{"label":"gbase-sink","path":"gbase-sink","category":"file"},{"label":"gbase-source","path":"gbase-source","category":"file"}]},{"label":"greenplum","category":"dir","children":[{"label":"greenplum-sink","path":"greenplum-sink","category":"file"},{"label":"greenplum-source","path":"greenplum-source","category":"file"}]},{"label":"hbase","category":"dir","children":[{"label":"hbase-lookup","path":"hbase-lookup","category":"file"},{"label":"hbase-sink","path":"hbase-sink","category":"file"},{"label":"hbase-source","path":"hbase-source","category":"file"}]},{"label":"hdfs","category":"dir","children":[{"label":"hdfs-sink","path":"hdfs-sink","category":"file"},{"label":"hdfs-source","path":"hdfs-source","category":"file"}]},{"label":"hive","category":"dir","children":[{"label":"hive-lookup","path":"hive-lookup","category":"file"},{"label":"hive-sink","path":"hive-sink","category":"file"}]},{"label":"influxdb","category":"dir","children":[{"label":"influxdb-sink","path":"influxdb-sink","category":"file"},{"label":"influxdb-source","path":"influxdb-source","category":"file"}]},{"label":"kafka","category":"dir","children":[{"label":"kafka-sink","path":"kafka-sink","category":"file"},{"label":"kafka-source","path":"kafka-source","category":"file"}]},{"label":"kingbase","category":"dir","children":[{"label":"kingbase-sink","path":"kingbase-sink","category":"file"},{"label":"kingbase-source","path":"kingbase-source","category":"file"}]},{"label":"kudu","category":"dir","children":[{"label":"kudu-lookup","path":"kudu-lookup","category":"file"},{"label":"kudu-sink","path":"kudu-sink","category":"file"},{"label":"kudu-source","path":"kudu-source","category":"file"}]},{"label":"logminer","category":"dir","children":[{"label":"LogMiner-source","path":"LogMiner-source","category":"file"},{"label":"LogMiner原理","path":"LogMiner原理","category":"file"},{"label":"LogMiner配置","path":"LogMiner配置","category":"file"}]},{"label":"mongodb","category":"dir","children":[{"label":"mongodb-lookup","path":"mongodb-lookup","category":"file"},{"label":"mongodb-sink","path":"mongodb-sink","category":"file"},{"label":"mongodb-source","path":"mongodb-source","category":"file"}]},{"label":"mysql","category":"dir","children":[{"label":"mysql-lookup","path":"mysql-lookup","category":"file"},{"label":"mysql-sink","path":"mysql-sink","category":"file"},{"label":"mysql-source","path":"mysql-source","category":"file"}]},{"label":"oracle","category":"dir","children":[{"label":"oracle-lookup","path":"oracle-lookup","category":"file"},{"label":"oracle-sink","path":"oracle-sink","category":"file"},{"label":"oracle-source","path":"oracle-source","category":"file"}]},{"label":"pgwal","category":"dir","children":[{"label":"Postgres-CDC","path":"Postgres-CDC","category":"file"}]},{"label":"postgresql","category":"dir","children":[{"label":"postgres-lookup","path":"postgres-lookup","category":"file"},{"label":"postgres-sink","path":"postgres-sink","category":"file"},{"label":"postgres-source","path":"postgres-source","category":"file"}]},{"label":"rocketmq","category":"dir","children":[{"label":"rocketmq-source","path":"rocketmq-source","category":"file"}]},{"label":"saphana","category":"dir","children":[{"label":"saphana-sink","path":"saphana-sink","category":"file"},{"label":"saphana-source","path":"saphana-source","category":"file"}]},{"label":"sqlserver","category":"dir","children":[{"label":"sqlserver-lookup","path":"sqlserver-lookup","category":"file"},{"label":"sqlserver-sink","path":"sqlserver-sink","category":"file"},{"label":"sqlserver-source","path":"sqlserver-source","category":"file"}]},{"label":"sqlservercdc","category":"dir","children":[{"label":"SqlServer CDC实时采集原理","path":"SqlServer CDC实时采集原理","category":"file"},{"label":"SqlServer配置CDC","path":"SqlServer配置CDC","category":"file"},{"label":"SqlserverCDC-source","path":"SqlserverCDC-source","category":"file"}]}],"category":"dir"},{"label":"开发者指南","children":[{"label":"如何提交一个优秀的PR","path":"如何提交一个优秀的PR","category":"file"},{"label":"如何自定义插件","path":"如何自定义插件","category":"file"}],"category":"dir"},{"label":"拓展功能","children":[{"label":"增量同步介绍","path":"增量同步介绍","category":"file"},{"label":"断点续传介绍","path":"断点续传介绍","category":"file"},{"label":"脏数据插件设计","path":"脏数据插件设计","category":"file"}],"category":"dir"}],"toc":[{"text":"HDFS Source","level":1,"id":"a4f23d41-0b77-44dd-b8cc-0758b5ce0fbb"},{"text":"一、介绍","level":2,"id":"beef7c19-6d64-4b4f-9172-246874bd780b"},{"text":"二、支持版本","level":2,"id":"48d2a200-9a7e-4c5b-b0d9-3cf8602eec47"},{"text":"三、插件名称","level":2,"id":"a4875eb4-a9b1-4f69-84f1-a1f2d97ec2a6"},{"text":"四、参数说明","level":2,"id":"f2f0b07a-bb03-478a-ade6-151d9be5f44a"},{"text":"1、Sync","level":3,"id":"c01e09c1-94d2-4285-980b-f872028c9c29"},{"text":"2、SQL","level":3,"id":"6a22d1ab-20ad-4f85-8428-94a7c73b7e5f"},{"text":"五、数据类型","level":2,"id":"253c10f1-c7ad-4d58-abc0-5c2058d7daae"},{"text":"六、脚本示例","level":2,"id":"e9c9edf4-9585-4898-9655-342e2e75e93d"}]},"__N_SSG":true}