# 快速开始

本文讨论如何在不同场景下使用纯钧进行同步/SQL计算任务。本文中以 Stream -> Stream 为例子说明，如需构建其他数据源任务，请根据插件文档具体修改。

# 准备开始

操作系统：无限制

系统版本：无限制

### 环境要求

#### java

- JDK1.8
- 配置好JAVA_HOME环境变量

> jdk安装步骤这里不做介绍

#### Flink

- 推荐flink1.12.7
- 官网下载压缩包直接解压即可
    - 下载地址：https://dlcdn.apache.org/flink/flink-1.12.7/flink-1.12.7-bin-scala_2.12.tgz
- 需要在提交机器上配置FLINK_HOME环境变量
- yarn-session和yarn-perJob任务需要额外在$FLINK_HOME/lib/目录下加入flink-shaded-hadoop-2-uber-2.7.5-10.0.jar文件
    - 下载地址：https://repo1.maven.org/maven2/org/apache/flink/flink-shaded-hadoop-2/2.7.5-10.0/flink-shaded-hadoop-2-2.7.5-10.0.jar

> local模式不需要安装Flink

#### Hadoop

- 推荐hadoop2.7.5
- 需要在提交机器上配置HADOOP_HOME环境变量

> local模式和standalone模式无需依赖Hadoop环境

# 获取插件

纯钧提供了已经编译好的插件压缩包（[chunjun-dist.tar](https://github.com/DTStack/chunjun/releases)），里面包含目前所有的脚本案例，任务提交脚本，插件包等内容，使得用户可以直接下载，根据需要配置任务，开箱即用。

另外，可以下载源码（[github地址](https://github.com/DTStack/chunjun)），自行编译源码，提交任务。

## 压缩包

纯钧提供的压缩包（chunjun-dist.tar）里包含四部分内容：bin（包含任务提交脚本），chunjun-dist（纯钧任务插件包），chunjun-example（纯钧任务脚本模版），lib（任务提交客户端），用户可以通过bin里的提交脚本，使用已经编译好的插件jar包直接提交任务，无需关心插件编译过程，适合调研使用。

## 源码编译

### 获取代码
1.使用git工具把项目clone到本地

```
git clone https://github.com/DTStack/chunjun.git
cd chunjun
```

### 插件编译
在chunjun目录下执行

```bash
mvn clean package -DskipTests 
```

或者执行

```bash
sh build/build.sh
```

执行完上述命令之后，在chunjun-assembly模块的target目录会得到一个完整的安装包

### 多平台兼容

chunjun目前支持tdh和开源hadoop平台，对不同的平台有需要使用不同的maven命令打包

| 平台类型 |                                              | 含义                                    |
| -------- | -------------------------------------------- | --------------------------------------- |
| tdh      | mvn clean package -DskipTests -P default,tdh | 打包出inceptor插件以及default支持的插件 |
| default  | mvn clean package -DskipTests -P default     | 除了inceptor插件之外的所有插件          |

### 常见问题

#### 1.编译找不到DB2、达梦、gbase、ojdbc8等驱动包

解决办法：在$CHUNJUN_HOME/jars目录下有这些驱动包，可以手动安装，也可以使用插件提供的脚本安装：

```bash
## windows平台
./$CHUNJUN_HOME/bin/install_jars.bat

## unix平台
./$CHUNJUN_HOME/bin/install_jars.sh
```

# 任务提交

纯钧支持多种模式提交任务，在生产环境中，常用的模式有yarn-session和 yarn-pre-job 模式。
在开始前请先确保环境安装正确。

视频不演示资源下载过程以及jdk、hadoop环境的安装过程

[视频链接](https://www.bilibili.com/video/BV1ZS4y1H74k?spm_id_from=333.999.0.0)

## 参数说明

mode：任务提交的类型，非必填项，类型有：local（默认值），standalone，yarn-session，yarn-per-job，kubernetes-session，kubernetes-application，对应源码中枚举类 **ClusterMode**；

jobType：纯钧任务类型，必填项，同步任务为：sync，SQL计算任务为：sql；

job：纯钧任务脚本地址，必填项；

chunjunDistDir：纯钧插件包地址；

confProp：纯钧任务配置参数，Flink相关配置也是在这里配置；

flinkConfDir：flink-conf.yaml 地址，在非local模式时，需要配置；

## Local

Local 模式不依赖Flink环境和Hadoop环境，在本地环境启动一个JVM进程执行纯钧任务。

### 提交步骤

进入到chunjun-dist 目录，执行命令

```shell
sh bin/chunjun-local.sh  -job chunjun-examples/json/stream/stream.json
```

即可执行一个简单的 **stream -> stream** 同步任务

[参考视频](https://www.bilibili.com/video/BV1mT411g7fJ?spm_id_from=333.999.0.0)

## Standalone

Standalone模式依赖Flink Standalone环境，不依赖Hadoop环境。

### 提交步骤

#### 1. 启动Flink Standalone环境

```shell
bash $FLINK_HOME/bin/start-cluster.sh
```

启动成功后默认端口为8081，我们可以访问当前机器的8081端口进入standalone的flink web ui

#### 2. 提交任务

进入到本地chunjun-dist目录，执行命令

```shell
sh bin/chunjun-standalone.sh -job chunjun-examples/json/stream/stream.json
```

提交成功之后，可以在flink web ui 上观察任务情况；

[参考视频](https://www.bilibili.com/video/BV1TT41137UV?spm_id_from=333.999.0.0)

## Yarn Session

YarnSession 模式依赖Flink 和 Hadoop 环境，需要在任务提交之前启动相应的yarn session；

### 提交步骤

#### 1. 启动yarn session环境

Yarn Pre-Job 模式依赖Flink 和 Hadoop 环境，需要在提交机器中提前设置好$HADOOP_HOME和$FLINK_HOME

我们需要使用yarn-session -t参数上传chunjun-dist

```shell
cd $FLINK_HOME/bin
./yarn-session -t $CHUNJUN_HOME -d
```

#### 2. 提交任务

通过yarn web ui 查看session 对应的application $SESSION_APPLICATION_ID，进入到本地chunjun-dist目录，执行命令

```shell
sh ./bin/chunjun-yarn-session.sh -job chunjun-examples/json/stream/stream.json -confProp {\"yarn.application.id\":\"SESSION_APPLICATION_ID\"}
```

yarn.application.id 也可以在 flink-conf.yaml 中设置；提交成功之后，可以通过 yarn web ui 上观察任务情况。

[参考视频](https://www.bilibili.com/video/BV1oU4y1D7e7?spm_id_from=333.999.0.0)

## Yarn Per-Job

Yarn Per-Job 模式依赖Flink 和 Hadoop 环境，需要在提交机器中提前设置好$HADOOP_HOME和$FLINK_HOME。

### 提交步骤

Yarn Per-Job 提交任务配置正确即可提交。进入本地chunjun-dist目录，执行命令提交任务。

```shell
sh ./bin/chunjun-yarn-perjob.sh -job chunjun-examples/json/stream/stream.json
```

提交成功之后，可以通过 yarn web ui 上观察任务情况；

[参考视频](https://www.bilibili.com/video/BV1oU4y1D7e7?spm_id_from=333.999.0.0)


# docker 构建
执行如下命令，执行完成后在本地生成一个名为 chunjun-master的镜像（注意：需要预先完成maven打包）
```shell
sh ./bin/chunjun-docker.sh
```
预先提供了一个公共镜像 dtopensource/chunjun-master
## 如何使用
### 直接启动
默认使用chunjun-examples/json/stream/stream.json这个任务，standalone模式
docker run -p 8081:8081 dtopensource/chunjun-master
### 指定文件
假设在你机器上的文件是/chunjun/chunjun-examples/json/stream/stream.json，docker内挂载的目录必须是/opt/flink/job
任务类型根据文件名自动推断：例如stream.json是sync任务，stream.sql是sql任务
docker run -p 8081:8081 -v /chunjun/chunjun-examples/json/stream/stream.json:/opt/flink/job/stream.json dtopensource/chunjun-master
### 指定模式
通过-m参数指定模式，可选项local、standalone，默认为standalone模式
在standalone模式下，可以通过web查看任务，默认地址是localhost:8081，注意此时docker 容器不会主动退出，另开终端通过docker stop 退出。
docker run -p 8081:8081 dtopensource/chunjun-master -m local
### 其他说明
如果数据源中有外部机器，需要传入host信息
docker run -p 8081:8081 --add-host=www.test.com:192.168.100.100 dtopensource/chunjun-master

